{"gen_pttchat : pttchat": {"id": "gen_pttchat", "filename": "pttchat", "fullname": "PTT八卦版中文對話語料", "task": "gen", "description": "\n    嗨，這裡是 PTT 中文語料集，我透過某些假設與方法 將每篇文章化簡為問答配對，其中問題來自文章的標題，而回覆是該篇文章的推文。\n    ", "ref": {"Source": "https://github.com/zake7749/Gossiping-Chinese-Corpus"}, "files": ["pttchat"]}, "tag_clner : clner-train": {"id": "tag_clner", "filename": "clner-train", "fullname": "Chinese-Literature-NER-RE-Dataset", "task": "tag", "description": "We provide a new Chinese literature dataset for Named Entity Recognition (NER) and Relation Extraction (RE). We define 7 entity tags and 9 relation tags based on several available NER and RE datasets but with some additional categories specific to Chinese literature text. ", "ref": {"Source": "https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset", "Paper": "https://arxiv.org/pdf/1711.07010.pdf"}, "files": ["clner-train", "clner-test", "clner-validation"]}, "tag_clner : clner-test": {"id": "tag_clner", "filename": "clner-test", "fullname": "Chinese-Literature-NER-RE-Dataset", "task": "tag", "description": "We provide a new Chinese literature dataset for Named Entity Recognition (NER) and Relation Extraction (RE). We define 7 entity tags and 9 relation tags based on several available NER and RE datasets but with some additional categories specific to Chinese literature text. ", "ref": {"Source": "https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset", "Paper": "https://arxiv.org/pdf/1711.07010.pdf"}, "files": ["clner-train", "clner-test", "clner-validation"]}, "tag_clner : clner-validation": {"id": "tag_clner", "filename": "clner-validation", "fullname": "Chinese-Literature-NER-RE-Dataset", "task": "tag", "description": "We provide a new Chinese literature dataset for Named Entity Recognition (NER) and Relation Extraction (RE). We define 7 entity tags and 9 relation tags based on several available NER and RE datasets but with some additional categories specific to Chinese literature text. ", "ref": {"Source": "https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset", "Paper": "https://arxiv.org/pdf/1711.07010.pdf"}, "files": ["clner-train", "clner-test", "clner-validation"]}, "tag_cged : cged": {"id": "tag_cged", "filename": "cged", "fullname": "中文語法錯誤診斷 - Chinese Grammatical Error Diagnosis", "task": "tag", "description": "The grammatical errors are broadly categorized into 4 error types: word ordering, redundant, missing, and incorrect selection of linguistic components (also called PADS error types, denoting errors of Permutation, Addition, Deletion, and Selection, correspondingly).", "ref": {"Project Page": "http://nlp.ee.ncu.edu.tw/resource/cged.html"}, "files": ["cged"]}, "qa_zh : drcd-train": {"id": "qa_zh", "filename": "drcd-train", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : drcd-test": {"id": "qa_zh", "filename": "drcd-test", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : drcd-dev": {"id": "qa_zh", "filename": "drcd-dev", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : cmrc-train": {"id": "qa_zh", "filename": "cmrc-train", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : cmrc-test": {"id": "qa_zh", "filename": "cmrc-test", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : cmrc-dev": {"id": "qa_zh", "filename": "cmrc-dev", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : cail-train": {"id": "qa_zh", "filename": "cail-train", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : cail-test": {"id": "qa_zh", "filename": "cail-test", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : cail-dev": {"id": "qa_zh", "filename": "cail-dev", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : combine-train": {"id": "qa_zh", "filename": "combine-train", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "qa_zh : combine-test": {"id": "qa_zh", "filename": "combine-test", "fullname": "多個抽取式的中文閱讀理解資料集", "task": "qa", "description": "有DRCD/CMRC/CAIL三個資料集", "ref": {"DRCD Source": "https://github.com/DRCKnowledgeTeam/DRCD", "CMRC2018 Source": "https://github.com/ymcui/cmrc2018", "CAIL2019 Source": "https://github.com/iFlytekJudiciary/CAIL2019_CJRC"}, "files": ["drcd-train", "drcd-test", "drcd-dev", "cmrc-train", "cmrc-test", "cmrc-dev", "cail-train", "cail-test", "cail-dev", "combine-train", "combine-test"]}, "clas_udicstm : udicstm": {"id": "clas_udicstm", "filename": "udicstm", "fullname": "UDIC Sentiment Analysis Dataset", "task": "clas", "description": "正面情緒：約有309163筆，44M / 負面情緒：約有320456筆，15M", "ref": {"Source": "https://github.com/UDICatNCHU/UdicOpenData"}, "files": ["udicstm"]}, "gen_dream : dream": {"id": "gen_dream", "filename": "dream", "fullname": "周公解夢資料集", "task": "gen", "description": "透過夢境解析徵兆", "ref": {"Source": "https://github.com/saiwaiyanyu/tensorflow-bert-seq2seq-dream-decoder"}, "files": ["dream"]}, "clas_lihkgcat : lihkgcat": {"id": "clas_lihkgcat", "filename": "lihkgcat", "fullname": "LIHKG Post Title 分類資料", "task": "clas", "description": "根據title去分析屬於邊一個台", "ref": {"Source": "https://github.com/ylchan87/LiHKG_Post_NLP"}, "files": ["lihkgcat"]}, "gen_mt : engcmn": {"id": "gen_mt", "filename": "engcmn", "fullname": "Tab-delimited Bilingual Sentence Pairs", "task": "gen", "description": "English + TAB + The Other Language + TAB + Attribution", "ref": {"Source": "http://www.manythings.org/anki/"}, "files": ["engcmn", "engyue"]}, "gen_mt : engyue": {"id": "gen_mt", "filename": "engyue", "fullname": "Tab-delimited Bilingual Sentence Pairs", "task": "gen", "description": "English + TAB + The Other Language + TAB + Attribution", "ref": {"Source": "http://www.manythings.org/anki/"}, "files": ["engcmn", "engyue"]}, "clas_mathqa : mathqa-train": {"id": "clas_mathqa", "filename": "mathqa-train", "fullname": "Math QA", "task": "clas", "description": "Our dataset is gathered by using a new representation language to annotate over the AQuA-RAT dataset. AQuA-RAT has provided the questions, options, rationale, and the correct options.", "ref": {"Source url": "https://math-qa.github.io/math-QA/data/MathQA.zip"}, "files": ["mathqa-train", "mathqa-validation", "mathqa-test"]}, "clas_mathqa : mathqa-validation": {"id": "clas_mathqa", "filename": "mathqa-validation", "fullname": "Math QA", "task": "clas", "description": "Our dataset is gathered by using a new representation language to annotate over the AQuA-RAT dataset. AQuA-RAT has provided the questions, options, rationale, and the correct options.", "ref": {"Source url": "https://math-qa.github.io/math-QA/data/MathQA.zip"}, "files": ["mathqa-train", "mathqa-validation", "mathqa-test"]}, "clas_mathqa : mathqa-test": {"id": "clas_mathqa", "filename": "mathqa-test", "fullname": "Math QA", "task": "clas", "description": "Our dataset is gathered by using a new representation language to annotate over the AQuA-RAT dataset. AQuA-RAT has provided the questions, options, rationale, and the correct options.", "ref": {"Source url": "https://math-qa.github.io/math-QA/data/MathQA.zip"}, "files": ["mathqa-train", "mathqa-validation", "mathqa-test"]}, "clas_snli : snli-train": {"id": "clas_snli", "filename": "snli-train", "fullname": "Stanford Natural Language Inference (SNLI) Corpus", "task": "clas", "description": "The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).", "ref": {"Home page": "https://nlp.stanford.edu/projects/snli/"}, "files": ["snli-train", "snli-validation", "snli-test"]}, "clas_snli : snli-validation": {"id": "clas_snli", "filename": "snli-validation", "fullname": "Stanford Natural Language Inference (SNLI) Corpus", "task": "clas", "description": "The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).", "ref": {"Home page": "https://nlp.stanford.edu/projects/snli/"}, "files": ["snli-train", "snli-validation", "snli-test"]}, "clas_snli : snli-test": {"id": "clas_snli", "filename": "snli-test", "fullname": "Stanford Natural Language Inference (SNLI) Corpus", "task": "clas", "description": "The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE).", "ref": {"Home page": "https://nlp.stanford.edu/projects/snli/"}, "files": ["snli-train", "snli-validation", "snli-test"]}}